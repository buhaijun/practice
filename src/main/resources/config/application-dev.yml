server:
  port: 18080
  address: 0.0.0.0

spring:
  kafka:
    bootstrap-servers: 192.168.88.10:9092 # 指定kafka server的地址，集群配多个，中间，逗号隔开
    consumer:
      group-id: practice-kafka-demo-consumer
      ## smallest和largest才有效，如果smallest重新0开始读取，如果是largest从logfile的offset读取。一般情况下我们都是设置smallest
      auto-offset-reset: latest
      enable-auto-commit: true # enable.auto.commit:true --> 设置自动提交offset
      auto-commit-interval: 5000 #如果'enable.auto.commit'为true，则消费者偏移自动提交给Kafka的频率（以毫秒为单位），默认值为5000。
  redis:
    database: 0
    host: 127.0.0.1
    port: 6379
    password:
    lettuce:
      pool:
        max-active: 8 #最大连接数
        max-idle: 8 #最大空闲连接
        min-idle: 0 #最小空闲连接
  # 分库分表 多主 多从模式
  datasource:
    dynamic:
      druid:
        hikari:
          minimum-idle: 5
          maximum-pool-size: 15
          auto-commit: true
          idle-timeout: 30000
          pool-name: HikariCp
          max-lifetime: 1800000
          connection-timeout: 30000
          connection-test-query: SELECT 1
      datasource:
        # 主
        master:
          url: jdbc:mysql://localhost:3306/practice?useUnicode=true&characterEncoding=UTF-8&serverTimezone=Asia/Shanghai
          username: root
          password: 1QAZ2Wsx
          driver-class-name: com.mysql.cj.jdbc.Driver
          # 从
        gbase1:
          url: jdbc:mysql://localhost:3306/practice_slave_1?useUnicode=true&characterEncoding=UTF-8&serverTimezone=Asia/Shanghai
          username: root
          password: 1QAZ2Wsx
          driver-class-name: com.mysql.cj.jdbc.Driver

accidPrefix:
  user: practice

customer:
  #超级管理员手机号
  ADMIN_ID:
